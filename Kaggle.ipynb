{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <center><h2>By : Chirag Juyal [CS17MTECH11014]</h2></center>  \n",
    "</html>\n",
    "<br/>\n",
    "<br/>\n",
    "<p>Kaggle Challenge (<b>whats-cooking</b>) code base. Here three algorithms are used to solve the challenge, first is KNN, second is Decision Tree, and third is Naive Bayes. As a part of assignment, <b>deliverable (a) the code</b> is here as per the algorithms used in the consecutive cells below and <b>deliverable (b) the description of the algorithms used</b> follow their code cell in top to bottom order. <b>Deliverable (c) the analysis of the top 2 scoring algorithms</b> is in the last cell.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <center> <h3> K-Nearest Neighbor (Accuracy Score: 50.884 with K as 10)</h3></center>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra.\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv).\n",
    "import json # read json file.\n",
    "\n",
    "# Get the data from the json file.\n",
    "json_training_data = open(\"train.json\").read()\n",
    "json_testing_data = open(\"test.json\").read()\n",
    "tempTrainData = json.loads(json_training_data)\n",
    "tempTestData = json.loads(json_testing_data)\n",
    "trainDataframe = pd.DataFrame(tempTrainData)\n",
    "testDataframe = pd.DataFrame(tempTestData)\n",
    "trainDic = trainDataframe.to_dict()\n",
    "testDic = testDataframe.to_dict()\n",
    "\n",
    "# Get the unique features using set and then get a list of all such features.\n",
    "setOfFeatures = set()\n",
    "for i in range(len(trainDic['ingredients'])):\n",
    "    setOfFeatures.update(trainDic['ingredients'][i])\n",
    "featuresList = list(setOfFeatures)\n",
    "featuresList.sort()\n",
    "\n",
    "# Generate the feature matrix (X) and the target vector (Y) for training data.\n",
    "trainX = np.zeros((len(trainDic['ingredients']), len(setOfFeatures)), dtype=np.int)\n",
    "trainY = []\n",
    "for i in range(len(trainDic['ingredients'])):\n",
    "    featureSet = set()\n",
    "    k = 0\n",
    "    featureSet.update(trainDic['ingredients'][i])\n",
    "    featureList = list(featureSet)\n",
    "    featureList.sort()\n",
    "    trainY.append(trainDic['cuisine'][i])\n",
    "    for j in range(len(setOfFeatures)):\n",
    "        if(featureList[k] == featuresList[j]):\n",
    "            trainX[i][j] = 1\n",
    "            k += 1\n",
    "            if(k == len(featureList)):\n",
    "                break;\n",
    "\n",
    "# Generate the feature matrix (X) for testing data.\n",
    "testX = np.zeros((len(testDic['ingredients']), len(setOfFeatures)), dtype=np.int)\n",
    "for i in range(len(testDic['ingredients'])):\n",
    "    featureSet = set()\n",
    "    k = 0\n",
    "    featureSet.update(testDic['ingredients'][i])\n",
    "    featureList = list(featureSet)\n",
    "    featureList.sort()\n",
    "    for j in range(len(setOfFeatures)):\n",
    "        if(featureList[k] == featuresList[j]):\n",
    "            testX[i][j] = 1\n",
    "            k += 1\n",
    "            if(k == len(featureList)):\n",
    "                break;\n",
    "\n",
    "# Create the instance of KNN and then fit the training data and then predict the test Data.     \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "KNN = KNeighborsClassifier(n_neighbors = 5)\n",
    "KNN.fit(trainX,trainY)\n",
    "predicted = KNN.predict(testX)\n",
    "\n",
    "# WRite the results on a file.\n",
    "import csv\n",
    "with open('submission.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    lines = []\n",
    "    lines.append(['id', 'cuisine'])\n",
    "    for i in range(len(predicted)):\n",
    "        lines.append([testDic['id'][i],predicted[i]])\n",
    "    writer.writerows(lines)\n",
    "    writeFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Description :</b> <p>Predefined library of KNeighborsClassifier by sklearn is used to predict. The preprocessing of data is done by first getting the distinct features in the training data set and then creating a matrix of #_of_data_entries X #_of_distinct_ingedients. The complete data is then defined as rows of this matrix where value 1 against an ingredient means that ingredient is present and 0 means its not present in the cuisine. The KNN as we know fit the data in the # of distinct ingredients-dimentions first. And then for each data entry in the test set calculate the distance of this new data entry with all the remaining data points fitted already and then look for K nearest neighbors in my case the value of K was 10. The algorithm took a lot of time to predict and was very slow and accuracy was also affected by curse of dimensionality.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <center> <h3> Decision Tree (Accuracy Score: 61.484)</h3></center>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra.\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv).\n",
    "import json # read json file.\n",
    "\n",
    "# Get the data from the json file. \n",
    "json_training_data = open(\"train.json\").read()\n",
    "json_testing_data = open(\"test.json\").read()\n",
    "tempTrainData = json.loads(json_training_data)\n",
    "tempTestData = json.loads(json_testing_data)\n",
    "trainDataframe = pd.DataFrame(tempTrainData)\n",
    "testDataframe = pd.DataFrame(tempTestData)\n",
    "trainDic = trainDataframe.to_dict()\n",
    "testDic = testDataframe.to_dict()\n",
    "\n",
    "# Get the unique features using set and then get a list of all such features.\n",
    "setOfFeatures = set()\n",
    "for i in range(len(trainDic['ingredients'])):\n",
    "    setOfFeatures.update(trainDic['ingredients'][i])\n",
    "featuresList = list(setOfFeatures)\n",
    "featuresList.sort()\n",
    "\n",
    "# Generate the feature matrix (X) and the target vector (Y) for training data.\n",
    "trainX = np.zeros((len(trainDic['ingredients']), len(setOfFeatures)), dtype=np.int)\n",
    "trainY = []\n",
    "for i in range(len(trainDic['ingredients'])):\n",
    "    featureSet = set()\n",
    "    k = 0\n",
    "    featureSet.update(trainDic['ingredients'][i])\n",
    "    featureList = list(featureSet)\n",
    "    featureList.sort()\n",
    "    trainY.append(trainDic['cuisine'][i])\n",
    "    for j in range(len(setOfFeatures)):\n",
    "        if(featureList[k] == featuresList[j]):\n",
    "            trainX[i][j] = 1\n",
    "            k += 1\n",
    "            if(k == len(featureList)):\n",
    "                break;\n",
    "\n",
    "# Generate the feature matrix (X) for testing data.\n",
    "testX = np.zeros((len(testDic['ingredients']), len(setOfFeatures)), dtype=np.int)\n",
    "for i in range(len(testDic['ingredients'])):\n",
    "    featureSet = set()\n",
    "    k = 0\n",
    "    featureSet.update(testDic['ingredients'][i])\n",
    "    featureList = list(featureSet)\n",
    "    featureList.sort()\n",
    "    for j in range(len(setOfFeatures)):\n",
    "        if(featureList[k] == featuresList[j]):\n",
    "            testX[i][j] = 1\n",
    "            k += 1\n",
    "            if(k == len(featureList)):\n",
    "                break;\n",
    "\n",
    "# Create the instance of Decision Tree and then fit the training data and then predict the test Data.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT = DecisionTreeClassifier(max_depth = 500)\n",
    "DT.fit(trainX,trainY)\n",
    "predicted = DT.predict(testX)\n",
    "\n",
    "# WRite the results on a file.\n",
    "import csv\n",
    "with open('submission.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    lines = []\n",
    "    lines.append(['id', 'cuisine'])\n",
    "    for i in range(len(predicted)):\n",
    "        lines.append([testDic['id'][i],predicted[i]])\n",
    "    writer.writerows(lines)\n",
    "    writeFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Description : </b> This algorithm gave me second best score out of the three algorithms I had tested upon. This algorithm uses decision tree classifier to classify data provided. The in-build function provided by sklearn is used. The decision tree classifier is passed with all the data, it uses the gini index by default criterion for selecting the best feature at the time of split. The tree is made selecting best feature that results in least impurity at the time and once the tree is constructed the test data is passed to check the predictions by the algorithm. The preprocessing of the data is same as above which is constructing the matrix of size the number of entries of data by number of distinct ingredients accorss all the training data. At the end the predictions are stored in the submiccion.csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <center> <h3> Multinomial Naive Bayes (Accuracy Score: 74.798)</h3></center>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra.\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv).\n",
    "import json # read json file.\n",
    "\n",
    "# Get the data from the json file. \n",
    "json_training_data = open(\"train.json\").read()\n",
    "json_testing_data = open(\"test.json\").read()\n",
    "tempTrainData = json.loads(json_training_data)\n",
    "tempTestData = json.loads(json_testing_data)\n",
    "trainDataframe = pd.DataFrame(tempTrainData)\n",
    "testDataframe = pd.DataFrame(tempTestData)\n",
    "trainDic = trainDataframe.to_dict()\n",
    "testDic = testDataframe.to_dict()\n",
    "\n",
    "# Get the unique features using set and then get a list of all such features.\n",
    "setOfFeatures = set()\n",
    "for i in range(len(trainDic['ingredients'])):\n",
    "    setOfFeatures.update(trainDic['ingredients'][i])\n",
    "featuresList = list(setOfFeatures)\n",
    "featuresList.sort()\n",
    "\n",
    "# Generate the feature matrix (X) and the target vector (Y) for training data.\n",
    "trainX = np.zeros((len(trainDic['ingredients']), len(setOfFeatures)), dtype=np.int)\n",
    "trainY = []\n",
    "for i in range(len(trainDic['ingredients'])):\n",
    "    featureSet = set()\n",
    "    k = 0\n",
    "    featureSet.update(trainDic['ingredients'][i])\n",
    "    featureList = list(featureSet)\n",
    "    featureList.sort()\n",
    "    trainY.append(trainDic['cuisine'][i])\n",
    "    for j in range(len(setOfFeatures)):\n",
    "        if(featureList[k] == featuresList[j]):\n",
    "            trainX[i][j] = 1\n",
    "            k += 1\n",
    "            if(k == len(featureList)):\n",
    "                break;\n",
    "\n",
    "# Generate the feature matrix (X) for testing data.\n",
    "testX = np.zeros((len(testDic['ingredients']), len(setOfFeatures)), dtype=np.int)\n",
    "for i in range(len(testDic['ingredients'])):\n",
    "    featureSet = set()\n",
    "    k = 0\n",
    "    featureSet.update(testDic['ingredients'][i])\n",
    "    featureList = list(featureSet)\n",
    "    featureList.sort()\n",
    "    for j in range(len(setOfFeatures)):\n",
    "        if(featureList[k] == featuresList[j]):\n",
    "            testX[i][j] = 1\n",
    "            k += 1\n",
    "            if(k == len(featureList)):\n",
    "                break;\n",
    "\n",
    "# Create the instance of Multinomial Naive Bayes and then fit the training data and then predict the test Data.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB = MultinomialNB(alpha=0.1)\n",
    "NB.fit(trainX,trainY)\n",
    "predicted = NB.predict(testX) \n",
    "\n",
    "# WRite the results on a file.\n",
    "import csv\n",
    "with open('submission.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    lines = []\n",
    "    lines.append(['id', 'cuisine'])\n",
    "    for i in range(len(predicted)):\n",
    "        lines.append([testDic['id'][i],predicted[i]])\n",
    "    writer.writerows(lines)\n",
    "    writeFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Description : </b> This is best algorithm been used out of all other with the maximium accuracy. Naive Bayes with mutinomial as the classification have around 19 different classes to be predicted. Naive Bayes as known has the least error rate which is proved with results as well. Naive Bayes as we know uses Bayes method to find the prediction. We pass the alpha parameter the smoothing factor as 0.1 which gave me the best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Analysis</h3></center>\n",
    "\n",
    "<ol>\n",
    "    <li>The best accuracy achieved is <b>74.798</b> by Naive Bayes and second best accuracy is <b>61.484</b> by Decision Tree.</li>\n",
    "    <li>KNN performed the worst and took the maximum time which was 10 times the time taken by other two algorithms.</li>\n",
    "    <li>Decision Tree with gini index (<b>61.031</b>) performed better than using entropy (<b>55.430</b>), as we know gini is to minimize the miss-classification and its computationally fast. </li>\n",
    "    <li>When the maximum depth of the decision tree was fixed to 1000 then the accuracy of the decission tree was incresed from <b>61.031</b> to <b>61.484</b>.</li>\n",
    "    <li>Naive Bayes provides minimum error rate is proved after applying naive bayes as, out of three algorithms used here.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
